{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Nl2Sql Flow using RAG (large database use case)\n",
    "\n",
    "1. Azure AI Search\n",
    "2. AzureOpenAI Embeddings (text-embeddings-ada-002)\n",
    "3. Azure OpenAI LLM (GPT-4-32k)\n",
    "4. Langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# pip install wget\n",
    "# pip install azure-search-documents \n",
    "# pip install azure-identity\n",
    "# pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Import required libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai  \n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from azure.search.documents.indexes.models import (\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    SearchField,\n",
    "    SearchableField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    "    SimpleField,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    VectorSearchProfile,\n",
    ")\n",
    "import sys\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, PromptTemplate\n",
    "from pandas import DataFrame as pd\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Configure OpenAI settings**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Langchain configuration variables\n",
    "LANGCHAIN_TRACING_V2 = \"true\"\n",
    "LANGCHAIN_API_KEY = os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "\n",
    "azure_openai_api_endpoint=os.getenv(\"Az_OPENAI_ENDPOINT\") \n",
    "azure_openai_api_version=os.getenv(\"Az_OPENAI_VERSION\") \n",
    "azure_openai_api_key = os.getenv(\"Az_OPENAI_KEY\") \n",
    "#azure_openai_api_type=\"azure\"\n",
    "azure_openai_deployment_model=os.getenv(\"Az_OPENAI_DEPLOYMENT_NAME\")\n",
    "azure_openai_embedding_model =\"text-embedding-ada-002\"#os.getenv(\"Az_OPENAI_EMB_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Use API key authentication\n",
    "client = AzureOpenAI(\n",
    "        api_key=azure_openai_api_key,\n",
    "        api_version=azure_openai_api_version,\n",
    "        azure_endpoint=azure_openai_api_endpoint,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Configure Azure AI Search Vector Store settings**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "search_service_endpoint = os.getenv(\"Az_SEARCH_ENDPOINT\")\n",
    "search_service_api_key = os.getenv(\"Az_SEARCH_KEY\")\n",
    "table_index_name = \"nl2sql-table-index\"\n",
    "column_index_name = \"nl2sql-columns-index\"\n",
    "\n",
    "credential = AzureKeyCredential(search_service_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Create index for tables**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_4.0 Function to generate embeddings, also used for query embeddings_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(text):\n",
    "    response = client.embeddings.create(input=text, model=azure_openai_embedding_model)\n",
    "    embedding = response.data[0].embedding\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Step 4.1 Tables Index Creation_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl2sql-table-index created\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SearchIndexClient\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_service_endpoint, credential=credential\n",
    ")\n",
    "\n",
    "# Define the fields for the index\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"dataset_name\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"table_name\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"description\", type=SearchFieldDataType.String),\n",
    "    SearchField(\n",
    "        name=\"example_queries\", \n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.String),\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"description_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        vector_search_dimensions=1536,\n",
    "        vector_search_profile_name=\"my-vector-config\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"my-hnsw\",\n",
    "            kind=VectorSearchAlgorithmKind.HNSW,\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"my-vector-config\",\n",
    "            algorithm_configuration_name=\"my-hnsw\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Configure the semantic search configuration\n",
    "semantic_search = SemanticSearch(\n",
    "    configurations=[\n",
    "        SemanticConfiguration(\n",
    "            name=\"my-semantic-config\",\n",
    "            prioritized_fields=SemanticPrioritizedFields(\n",
    "                title_field=SemanticField(field_name=\"dataset_name\"),\n",
    "                keywords_fields=[SemanticField(field_name=\"table_name\")],\n",
    "                content_fields=[SemanticField(field_name=\"description\")],\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the search index with the vector search and semantic search configurations\n",
    "index = SearchIndex(\n",
    "    name=table_index_name,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search,\n",
    "    semantic_search=semantic_search,\n",
    ")\n",
    "\n",
    "# Create or update the index\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f\"{result.name} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Step 4.2: Load tables metadata and generate embeddings_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read the text-sample.json\n",
    "with open(\"./tables.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    input_data = json.load(file)\n",
    "\n",
    "i = 0\n",
    "# Generate embeddings for dataset, table and description fields\n",
    "for item in input_data:\n",
    "    item[\"id\"] = str(i)\n",
    "    dataset = item[\"dataset_name\"]\n",
    "    table = item[\"table_name\"]\n",
    "    description = item[\"description\"]\n",
    "    examples = item[\"example_queries\"]\n",
    "\n",
    "    description_embeddings = generate_embeddings(description)\n",
    "    item[\"description_Vector\"] = description_embeddings\n",
    "    \n",
    "    i=i+1\n",
    "# Output embeddings to docVectors.json file\n",
    "with open(\"tableVectors.json\", \"w\") as f:\n",
    "    json.dump(input_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Step 4.3: Upload table documents to AI Search_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 34 documents\n"
     ]
    }
   ],
   "source": [
    "# Upload  embedding documents to the index\n",
    "with open(\"tableVectors.json\", \"r\") as file:\n",
    "    documents = json.load(file)\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_service_endpoint, index_name=table_index_name, credential=credential\n",
    ")\n",
    "result = search_client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Create index for columns**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Step 5.1: Column Index Creation_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl2sql-columns-index created\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SearchIndexClient\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_service_endpoint, credential=credential\n",
    ")\n",
    "\n",
    "# Define the fields for the index\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"dataset_name\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"table_name\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"column_name\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"description\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"usage\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"data_type\", type=SearchFieldDataType.String),\n",
    "    SearchField(\n",
    "        name=\"description_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        vector_search_dimensions=1536,\n",
    "        vector_search_profile_name=\"my-vector-config\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            kind=VectorSearchAlgorithmKind.HNSW,\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"my-vector-config\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Configure the semantic search configuration\n",
    "semantic_search = SemanticSearch(\n",
    "    configurations=[\n",
    "        SemanticConfiguration(\n",
    "            name=\"my-semantic-config\",\n",
    "            prioritized_fields=SemanticPrioritizedFields(\n",
    "                title_field=SemanticField(field_name=\"dataset_name\"),\n",
    "                keywords_fields=[SemanticField(field_name=\"table_name\"),SemanticField(field_name=\"column_name\")],\n",
    "                content_fields=[SemanticField(field_name=\"description\")],\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the search index with the vector search and semantic search configurations\n",
    "index = SearchIndex(\n",
    "    name=column_index_name,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search,\n",
    "    semantic_search=semantic_search,\n",
    ")\n",
    "\n",
    "# Create or update the index\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f\"{result.name} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_5.2: Load data and generate document embeddings_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Read the text-sample.json\n",
    "with open(\"./columns.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    input_data = json.load(file)\n",
    "\n",
    "i = 0\n",
    "# Generate embeddings for dataset, table and description fields\n",
    "for item in input_data:\n",
    "    item[\"id\"] = str(i)\n",
    "    dataset = item[\"dataset_name\"]\n",
    "    table = item[\"table_name\"]\n",
    "    column = item[\"column_name\"]\n",
    "    description = item[\"description\"]\n",
    "    usage = item[\"usage\"]\n",
    "    datatype = item[\"data_type\"]\n",
    "\n",
    "    description_embeddings = generate_embeddings(description)\n",
    "    item[\"description_Vector\"] = description_embeddings\n",
    "\n",
    "    i=i+1\n",
    "# Output embeddings to docVectors.json file\n",
    "with open(\"columnVectors.json\", \"w\") as f:\n",
    "    json.dump(input_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Step 5.3: upload documents to AI Search_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 67 documents\n"
     ]
    }
   ],
   "source": [
    "# Upload  embedding documents to the index\n",
    "with open(\"columnVectors.json\", \"r\") as file:\n",
    "    documents = json.load(file)\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_service_endpoint, index_name=column_index_name, credential=credential\n",
    ")\n",
    "result = search_client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Perform a vector similarity search on tables**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flight_reservations.reservations', 'hotel_reservations.reservations', 'flight_reservations.flights', 'flight_reservations.transactions', 'flight_reservations.customers']\n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search for tables\n",
    "query = \"Provide a list of all flight reservations from October 10th to November 15th, 2023\"\n",
    "  \n",
    "search_client = SearchClient(search_service_endpoint, table_index_name, credential)  \n",
    "vector_query = VectorizedQuery(vector=generate_embeddings(query), k_nearest_neighbors=5, fields=\"description_vector\")\n",
    "  \n",
    "matched_documents = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query], \n",
    "    select=[\"dataset_name\", \"table_name\", \"description\", \"example_queries\"],\n",
    "    search_mode=\"all\"\n",
    ")\n",
    "\n",
    "matched_tables = []\n",
    "for document in matched_documents:\n",
    "    dataset_name = document['dataset_name']\n",
    "    table_name = document['table_name']\n",
    "    matched_tables.append(f'{dataset_name}.{table_name}')\n",
    "  \n",
    "print(matched_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7: Perform a vector similarity search on columns**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'description': 'A unique identifier for each flight.', 'data_type': 'INT64', 'table_name': 'reservations', 'usage': 'Used to uniquely identify and manage flight records.', 'column_name': 'flight_id', 'dataset_name': 'flight_reservations', '@search.score': 0.83983755, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}, {'description': 'A unique identifier for each flight.', 'data_type': 'INT64', 'table_name': 'flights', 'usage': 'Used to uniquely identify and manage flight records.', 'column_name': 'flight_id', 'dataset_name': 'flight_reservations', '@search.score': 0.83983755, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}, {'description': 'The arrival time of the flight.', 'data_type': 'DATETIME', 'table_name': 'flights', 'usage': 'Informs users and helps them plan their travel.', 'column_name': 'arrival_datetime', 'dataset_name': 'flight_reservations', '@search.score': 0.83931977, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}, {'description': 'The departure time of the flight.', 'data_type': 'DATETIME', 'table_name': 'flights', 'usage': 'Informs users and helps them plan their travel.', 'column_name': 'departure_datetime', 'dataset_name': 'flight_reservations', '@search.score': 0.8384493, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}, {'description': 'A unique identifier for each reservation.', 'data_type': 'INT64', 'table_name': 'transactions', 'usage': 'Used to uniquely identify and manage reservation records.', 'column_name': 'reservation_id', 'dataset_name': 'flight_reservations', '@search.score': 0.8370583, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}, {'description': 'A unique identifier for each reservation.', 'data_type': 'INT64', 'table_name': 'reservations', 'usage': 'Used to uniquely identify and manage reservation records.', 'column_name': 'reservation_id', 'dataset_name': 'flight_reservations', '@search.score': 0.8370583, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}, {'description': 'Timestamp of when the reservation was made.', 'data_type': 'DATETIME', 'table_name': 'reservations', 'usage': 'Helps track reservation history and manage bookings.', 'column_name': 'reservation_datetime', 'dataset_name': 'flight_reservations', '@search.score': 0.83532035, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}, {'description': 'The price of the flight ticket.', 'data_type': 'FLOAT64', 'table_name': 'flights', 'usage': 'Informs users and is used during booking transactions.', 'column_name': 'price', 'dataset_name': 'flight_reservations', '@search.score': 0.83378994, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}, {'description': 'The arrival location of the flight.', 'data_type': 'STRING', 'table_name': 'flights', 'usage': 'Used to find flights and plan journeys.', 'column_name': 'destination', 'dataset_name': 'flight_reservations', '@search.score': 0.8317544, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}, {'description': 'The departure location of the flight.', 'data_type': 'STRING', 'table_name': 'flights', 'usage': 'Helps users find flights based on their travel plans.', 'column_name': 'origin', 'dataset_name': 'flight_reservations', '@search.score': 0.8288277, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}, {'description': 'The airline operating the flight.', 'data_type': 'STRING', 'table_name': 'flights', 'usage': 'Provides users with the choice of airline and informs about the operator.', 'column_name': 'carrier', 'dataset_name': 'flight_reservations', '@search.score': 0.82586575, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}, {'description': 'The status of the reservation (e.g., confirmed, cancelled).', 'data_type': 'STRING', 'table_name': 'reservations', 'usage': 'Informs users and staff of the current state of the reservation.', 'column_name': 'status', 'dataset_name': 'flight_reservations', '@search.score': 0.8252619, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}]\n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search for columns\n",
    "search_client = SearchClient(search_service_endpoint, column_index_name, credential)  \n",
    "vector_query = VectorizedQuery(vector=generate_embeddings(query), k_nearest_neighbors=20,fields=\"description_vector\")\n",
    "  \n",
    "matched_columns = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query], \n",
    "    select=[\"dataset_name\", \"table_name\", \"column_name\", \"description\", \"usage\", \"data_type\"],\n",
    "    search_mode=\"all\"\n",
    ")\n",
    "matched_columns\n",
    "\n",
    "matched_columns_filtered = []\n",
    "for document in matched_columns:\n",
    "    dataset_name = document['dataset_name']\n",
    "    table_name = document['table_name']\n",
    "    matched_tables.append(f'{dataset_name}.{table_name}')\n",
    "    if dataset_name == 'flight_reservations': # i hard coded the table name here for now, you just need to replace it with the code that loop through matched_tables\n",
    "         matched_columns_filtered.append(document)\n",
    "  \n",
    "print(matched_columns_filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8: Third filter on both tables and columns top k results from search**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name=flight_reservations|table_name=reservations|column_name=flight_id|data_type=INT64\n",
      "dataset_name=flight_reservations|table_name=flights|column_name=flight_id|data_type=INT64\n",
      "dataset_name=flight_reservations|table_name=flights|column_name=arrival_datetime|data_type=DATETIME\n",
      "dataset_name=flight_reservations|table_name=flights|column_name=departure_datetime|data_type=DATETIME\n",
      "dataset_name=flight_reservations|table_name=transactions|column_name=reservation_id|data_type=INT64\n",
      "dataset_name=flight_reservations|table_name=reservations|column_name=reservation_id|data_type=INT64\n",
      "dataset_name=flight_reservations|table_name=reservations|column_name=reservation_datetime|data_type=DATETIME\n",
      "dataset_name=flight_reservations|table_name=flights|column_name=price|data_type=FLOAT64\n",
      "dataset_name=flight_reservations|table_name=flights|column_name=destination|data_type=STRING\n",
      "dataset_name=flight_reservations|table_name=flights|column_name=origin|data_type=STRING\n",
      "dataset_name=flight_reservations|table_name=flights|column_name=carrier|data_type=STRING\n",
      "dataset_name=flight_reservations|table_name=reservations|column_name=status|data_type=STRING\n"
     ]
    }
   ],
   "source": [
    "matched_columns_cleaned = []\n",
    "\n",
    "for doc in matched_columns_filtered:\n",
    "    dataset_name = doc['dataset_name']\n",
    "    table_name = doc['table_name']\n",
    "    column_name = doc['column_name']\n",
    "    data_type = doc['data_type']\n",
    "    matched_columns_cleaned.append(f'dataset_name={dataset_name}|table_name={table_name}|column_name={column_name}|data_type={data_type}')\n",
    "    \n",
    "matched_columns_cleaned = '\\n'.join(matched_columns_cleaned)\n",
    "print(matched_columns_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 9: Text-to-SQL generation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "template = \"You are a SQL master expert capable of writing complex SQL queries in Microsoft Sql Server.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "messages.append(system_message_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "human_template = \"\"\"Given the following inputs:\n",
    "USER_QUERY:\n",
    "--\n",
    "{query}\n",
    "--\n",
    "MATCHED_SCHEMA: \n",
    "--\n",
    "{matched_schema}\n",
    "--\n",
    "Please construct a SQL query using the MATCHED_SCHEMA and the USER_QUERY provided above. \n",
    "\n",
    "IMPORTANT: Use ONLY the column names (column_name) mentioned in MATCHED_SCHEMA. DO NOT USE any other column names outside of this. \n",
    "IMPORTANT: Associate column_name mentioned in MATCHED_SCHEMA only to the table_name specified under MATCHED_SCHEMA.\n",
    "NOTE: Use SQL 'AS' statement to assign a new name temporarily to a table column or even a table wherever needed. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "human_message = HumanMessagePromptTemplate.from_template(human_template)\n",
    "messages.append(human_message)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a SQL master expert capable of writing complex SQL queries in Microsoft Sql Server.'),\n",
       " HumanMessage(content=\"Given the following inputs:\\nUSER_QUERY:\\n--\\nProvide a list of all flight reservations from October 10th to November 15th, 2023\\n--\\nMATCHED_SCHEMA: \\n--\\ndataset_name=flight_reservations|table_name=reservations|column_name=flight_id|data_type=INT64\\ndataset_name=flight_reservations|table_name=flights|column_name=flight_id|data_type=INT64\\ndataset_name=flight_reservations|table_name=flights|column_name=arrival_datetime|data_type=DATETIME\\ndataset_name=flight_reservations|table_name=flights|column_name=departure_datetime|data_type=DATETIME\\ndataset_name=flight_reservations|table_name=transactions|column_name=reservation_id|data_type=INT64\\ndataset_name=flight_reservations|table_name=reservations|column_name=reservation_id|data_type=INT64\\ndataset_name=flight_reservations|table_name=reservations|column_name=reservation_datetime|data_type=DATETIME\\ndataset_name=flight_reservations|table_name=flights|column_name=price|data_type=FLOAT64\\ndataset_name=flight_reservations|table_name=flights|column_name=destination|data_type=STRING\\ndataset_name=flight_reservations|table_name=flights|column_name=origin|data_type=STRING\\ndataset_name=flight_reservations|table_name=flights|column_name=carrier|data_type=STRING\\ndataset_name=flight_reservations|table_name=reservations|column_name=status|data_type=STRING\\n--\\nPlease construct a SQL query using the MATCHED_SCHEMA and the USER_QUERY provided above. \\n\\nIMPORTANT: Use ONLY the column names (column_name) mentioned in MATCHED_SCHEMA. DO NOT USE any other column names outside of this. \\nIMPORTANT: Associate column_name mentioned in MATCHED_SCHEMA only to the table_name specified under MATCHED_SCHEMA.\\nNOTE: Use SQL 'AS' statement to assign a new name temporarily to a table column or even a table wherever needed. \\n\")]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request = chat_prompt.format_prompt(query=query,\n",
    "                                    matched_schema=matched_columns_cleaned).to_messages()\n",
    "request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Create an instance of chat llm\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=azure_openai_api_endpoint,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_deployment=azure_openai_deployment_model,\n",
    "    openai_api_key=azure_openai_api_key,\n",
    "    openai_api_type=\"azure\",\n",
    "    temperature = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \n",
      "    r.reservation_id,\n",
      "    r.flight_id,\n",
      "    r.reservation_datetime,\n",
      "    r.status,\n",
      "    f.departure_datetime,\n",
      "    f.arrival_datetime,\n",
      "    f.price,\n",
      "    f.destination,\n",
      "    f.origin,\n",
      "    f.carrier\n",
      "FROM \n",
      "    flight_reservations.reservations AS r\n",
      "JOIN \n",
      "    flight_reservations.flights AS f\n",
      "ON \n",
      "    r.flight_id = f.flight_id\n",
      "WHERE \n",
      "    r.reservation_datetime BETWEEN '2023-10-10' AND '2023-11-15'\n",
      "ORDER BY \n",
      "    r.reservation_datetime;\n"
     ]
    }
   ],
   "source": [
    "#%%time \n",
    "response = llm.invoke(request)\n",
    "sql = '\\n'.join(response.content.strip().split('\\n')[1:-1])\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \n",
      "    r.reservation_id,\n",
      "    r.flight_id,\n",
      "    r.reservation_datetime,\n",
      "    r.status,\n",
      "    f.departure_datetime,\n",
      "    f.arrival_datetime,\n",
      "    f.price,\n",
      "    f.destination,\n",
      "    f.origin,\n",
      "    f.carrier\n",
      "FROM \n",
      "    flight_reservations.reservations AS r\n",
      "JOIN \n",
      "    flight_reservations.flights AS f\n",
      "ON \n",
      "    r.flight_id = f.flight_id\n",
      "WHERE \n",
      "    r.reservation_datetime BETWEEN '2023-10-10' AND '2023-11-15'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql = sql.replace('```sql', '')\n",
    "# sql = sql.replace('```', '')\n",
    "# print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user = \"sa\"\n",
    "db_password = \"password123\"\n",
    "db_host = \"localhost\"\n",
    "db_name = \"flight_reservations\"\n",
    "db_port = 3306\n",
    "\n",
    "db = SQLDatabase.from_uri(f\"mssql+pyodbc://{db_user}:{db_password}@{db_host}/{db_name}?driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mssql\n"
     ]
    }
   ],
   "source": [
    "print(db.dialect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(6, 6, datetime.datetime(2023, 10, 10, 10, 0), 'Confirmed', datetime.datetime(2023, 11, 25, 6, 0), datetime.datetime(2023, 11, 25, 14, 30), 550.0, 'JFK', 'SEA', 'United'), (7, 7, datetime.datetime(2023, 10, 12, 11, 30), 'Confirmed', datetime.datetime(2023, 11, 27, 20, 0), datetime.datetime(2023, 11, 27, 23, 30), 380.0, 'MIA', 'JFK', 'American'), (8, 8, datetime.datetime(2023, 10, 15, 13, 20), 'Confirmed', datetime.datetime(2023, 11, 30, 10, 0), datetime.datetime(2023, 11, 30, 13, 30), 380.0, 'JFK', 'MIA', 'American'), (9, 8, datetime.datetime(2023, 10, 20, 9, 0), 'Cancelled', datetime.datetime(2023, 11, 30, 10, 0), datetime.datetime(2023, 11, 30, 13, 30), 380.0, 'JFK', 'MIA', 'American'), (10, 8, datetime.datetime(2023, 10, 22, 15, 45), 'Confirmed', datetime.datetime(2023, 11, 30, 10, 0), datetime.datetime(2023, 11, 30, 13, 30), 380.0, 'JFK', 'MIA', 'American'), (11, 11, datetime.datetime(2023, 10, 25, 12, 30), 'Confirmed', datetime.datetime(2023, 12, 12, 10, 0), datetime.datetime(2023, 12, 12, 16, 30), 400.0, 'ORD', 'LAX', 'Alaska'), (12, 12, datetime.datetime(2023, 10, 28, 17, 10), 'Confirmed', datetime.datetime(2023, 12, 15, 18, 0), datetime.datetime(2023, 12, 15, 20, 30), 400.0, 'LAX', 'ORD', 'Alaska'), (13, 12, datetime.datetime(2023, 10, 30, 14, 50), 'Cancelled', datetime.datetime(2023, 12, 15, 18, 0), datetime.datetime(2023, 12, 15, 20, 30), 400.0, 'LAX', 'ORD', 'Alaska'), (14, 14, datetime.datetime(2023, 11, 2, 8, 20), 'Confirmed', datetime.datetime(2023, 12, 24, 22, 0), datetime.datetime(2023, 12, 25, 2, 30), 450.0, 'SEA', 'ORD', 'JetBlue'), (15, 14, datetime.datetime(2023, 11, 4, 10, 45), 'Confirmed', datetime.datetime(2023, 12, 24, 22, 0), datetime.datetime(2023, 12, 25, 2, 30), 450.0, 'SEA', 'ORD', 'JetBlue'), (16, 16, datetime.datetime(2023, 11, 8, 15, 30), 'Confirmed', datetime.datetime(2023, 12, 31, 7, 0), datetime.datetime(2023, 12, 31, 15, 30), 600.0, 'SEA', 'JFK', 'Frontier'), (17, 17, datetime.datetime(2023, 11, 11, 10, 15), 'Confirmed', datetime.datetime(2024, 1, 5, 9, 0), datetime.datetime(2024, 1, 5, 12, 30), 480.0, 'LAX', 'JFK', 'Delta')]\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "df = execute_query.invoke(sql)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "rephrase_answer = answer_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is the list of all flight reservations from October 10th to November 15th, 2023:\\n\\n1. **Reservation ID:** 6\\n   - **Flight ID:** 6\\n   - **Reservation DateTime:** 2023-10-10 10:00\\n   - **Status:** Confirmed\\n   - **Departure DateTime:** 2023-11-25 06:00\\n   - **Arrival DateTime:** 2023-11-25 14:30\\n   - **Price:** $550.00\\n   - **Destination:** JFK\\n   - **Origin:** SEA\\n   - **Carrier:** United\\n\\n2. **Reservation ID:** 7\\n   - **Flight ID:** 7\\n   - **Reservation DateTime:** 2023-10-12 11:30\\n   - **Status:** Confirmed\\n   - **Departure DateTime:** 2023-11-27 20:00\\n   - **Arrival DateTime:** 2023-11-27 23:30\\n   - **Price:** $380.00\\n   - **Destination:** MIA\\n   - **Origin:** JFK\\n   - **Carrier:** American\\n\\n3. **Reservation ID:** 8\\n   - **Flight ID:** 8\\n   - **Reservation DateTime:** 2023-10-15 13:20\\n   - **Status:** Confirmed\\n   - **Departure DateTime:** 2023-11-30 10:00\\n   - **Arrival DateTime:** 2023-11-30 13:30\\n   - **Price:** $380.00\\n   - **Destination:** JFK\\n   - **Origin:** MIA\\n   - **Carrier:** American\\n\\n4. **Reservation ID:** 9\\n   - **Flight ID:** 8\\n   - **Reservation DateTime:** 2023-10-20 09:00\\n   - **Status:** Cancelled\\n   - **Departure DateTime:** 2023-11-30 10:00\\n   - **Arrival DateTime:** 2023-11-30 13:30\\n   - **Price:** $380.00\\n   - **Destination:** JFK\\n   - **Origin:** MIA\\n   - **Carrier:** American\\n\\n5. **Reservation ID:** 10\\n   - **Flight ID:** 8\\n   - **Reservation DateTime:** 2023-10-22 15:45\\n   - **Status:** Confirmed\\n   - **Departure DateTime:** 2023-11-30 10:00\\n   - **Arrival DateTime:** 2023-11-30 13:30\\n   - **Price:** $380.00\\n   - **Destination:** JFK\\n   - **Origin:** MIA\\n   - **Carrier:** American\\n\\n6. **Reservation ID:** 11\\n   - **Flight ID:** 11\\n   - **Reservation DateTime:** 2023-10-25 12:30\\n   - **Status:** Confirmed\\n   - **Departure DateTime:** 2023-12-12 10:00\\n   - **Arrival DateTime:** 2023-12-12 16:30\\n   - **Price:** $400.00\\n   - **Destination:** ORD\\n   - **Origin:** LAX\\n   - **Carrier:** Alaska\\n\\n7. **Reservation ID:** 12\\n   - **Flight ID:** 12\\n   - **Reservation DateTime:** 2023-10-28 17:10\\n   - **Status:** Confirmed\\n   - **Departure DateTime:** 2023-12-15 18:00\\n   - **Arrival DateTime:** 2023-12-15 20:30\\n   - **Price:** $400.00\\n   - **Destination:** LAX\\n   - **Origin:** ORD\\n   - **Carrier:** Alaska\\n\\n8. **Reservation ID:** 13\\n   - **Flight ID:** 12\\n   - **Reservation DateTime:** 2023-10-30 14:50\\n   - **Status:** Cancelled\\n   - **Departure DateTime:** 2023-12-15 18:00\\n   - **Arrival DateTime:** 2023-12-15 20:30\\n   - **Price:** $400.00\\n   - **Destination:** LAX\\n   - **Origin:** ORD\\n   - **Carrier:** Alaska\\n\\n9. **Reservation ID:** 14\\n   - **Flight ID:** 14\\n   - **Reservation DateTime:** 2023-11-02 08:20\\n   - **Status:** Confirmed\\n   - **Departure DateTime:** 2023-12-24 22:00\\n   - **Arrival DateTime:** 2023-12-25 02:30\\n   - **Price:** $450.00\\n   - **Destination:** SEA\\n   - **Origin:** ORD\\n   - **Carrier:** JetBlue\\n\\n10. **Reservation ID:** 15\\n    - **Flight ID:** 14\\n    - **Reservation DateTime:** 2023-11-04 10:45\\n    - **Status:** Confirmed\\n    - **Departure DateTime:** 2023-12-24 22:00\\n    - **Arrival DateTime:** 2023-12-25 02:30\\n    - **Price:** $450.00\\n    - **Destination:** SEA\\n    - **Origin:** ORD\\n    - **Carrier:** JetBlue\\n\\n11. **Reservation ID:** 16\\n    - **Flight ID:** 16\\n    - **Reservation DateTime:** 2023-11-08 15:30\\n    - **Status:** Confirmed\\n    - **Departure DateTime:** 2023-12-31 07:00\\n    - **Arrival DateTime:** 2023-12-31 15:30\\n    - **Price:** $600.00\\n    - **Destination:** SEA\\n    - **Origin:** JFK\\n    - **Carrier:** Frontier\\n\\n12. **Reservation ID:** 17\\n    - **Flight ID:** 17\\n    - **Reservation DateTime:** 2023-11-11 10:15\\n    - **Status:** Confirmed\\n    - **Departure DateTime:** 2024-01-05 09:00\\n    - **Arrival DateTime:** 2024-01-05 12:30\\n    - **Price:** $480.00\\n    - **Destination:** LAX\\n    - **Origin:** JFK\\n    - **Carrier:** Delta'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "rephrase_answer\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": query, \"query\": sql, \"result\": df})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

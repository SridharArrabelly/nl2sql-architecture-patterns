{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Quick start\n",
    "###### url - https://python.langchain.com/docs/get_started/quickstart\n",
    "##### In this quickstart we'll show you how to:\n",
    "\n",
    "##### Get setup with LangChain, LangSmith and LangServe\n",
    "Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    " \n",
    "Use LangChain Expression Language, the protocol that LangChain is built on and which facilitates component chaining\n",
    "1. Build a simple application with LangChain\n",
    "2. Trace your application with LangSmith\n",
    "3. Serve your application with LangServe\n",
    "That's a fair amount to cover! Let's dive in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install langchain\n",
    "#pip install -U langchain-openai\n",
    "\n",
    "#Install LangSmith\n",
    "#export LANGCHAIN_TRACKING_V2=\"true\"\n",
    "#export LANGCHAIN_API_KEY=\"ls__c29aafda0c7c454ab7b807b2eadb26a3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for AzureChatOpenAI\n__root__\n  As of openai>=1.0.0, if `azure_deployment` (or alias `deployment_name`) is specified then `base_url` (or alias `openai_api_base`) should not be. If specifying `azure_deployment`/`deployment_name` then use `azure_endpoint` instead of `base_url`.\n\nFor example, you could specify:\n\nazure_deployment=\"https://xxx.openai.azure.com/\", deployment_name=\"my-deployment\"\n\nOr you can equivalently specify:\n\nbase_url=\"https://xxx.openai.azure.com/openai/deployments/my-deployment\" (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 22\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# AZURE_OPENAI_API_KEY\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# AZURE_OPENAI_ENDPOINT\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# AZURE_OPENAI_AD_TOKEN\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Create an instance of chat llm\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m llm \u001b[38;5;241m=\u001b[39m AzureChatOpenAI(\n\u001b[0;32m     23\u001b[0m  \n\u001b[0;32m     24\u001b[0m     openai_api_version\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_API_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     25\u001b[0m     azure_deployment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-35-turbo-16k\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# azure_endpoint=openai_api_base,\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# openai_api_version=openai_api_version,\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# azure_deployment=azure_deployment,\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# openai_api_key=openai_api_key,\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# openai_api_type=openai_api_type,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sarrabelly\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\load\\serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\sarrabelly\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for AzureChatOpenAI\n__root__\n  As of openai>=1.0.0, if `azure_deployment` (or alias `deployment_name`) is specified then `base_url` (or alias `openai_api_base`) should not be. If specifying `azure_deployment`/`deployment_name` then use `azure_endpoint` instead of `base_url`.\n\nFor example, you could specify:\n\nazure_deployment=\"https://xxx.openai.azure.com/\", deployment_name=\"my-deployment\"\n\nOr you can equivalently specify:\n\nbase_url=\"https://xxx.openai.azure.com/openai/deployments/my-deployment\" (type=value_error)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "# from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import openai\n",
    "\n",
    "# AZURE_OPENAI_API_KEY\n",
    "# AZURE_OPENAI_ENDPOINT\n",
    "# AZURE_OPENAI_AD_TOKEN\n",
    "# OPENAI_API_VERSION\n",
    "# OPENAI_PROXY\n",
    "# from langchain import LLMChain\n",
    "\n",
    "# # Load config values\n",
    "# #openai_api_base = 'https://bdl-openai-swedencentral-01.openai.azure.com'\n",
    "# openai_api_version = '2023-07-01-preview'\n",
    "# deployment_name = 'gpt-35-turbo-16k'\n",
    "# #openai_api_key = 'a24a2eebe4ab4c268f1107b6d978cbe3'\n",
    "# openai_api_type = \"azure\"\n",
    "\n",
    "# Create an instance of chat llm\n",
    "llm = AzureChatOpenAI(\n",
    " \n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=\"gpt-35-turbo-16k\"\n",
    "    # azure_endpoint=openai_api_base,\n",
    "    # openai_api_version=openai_api_version,\n",
    "    # azure_deployment=azure_deployment,\n",
    "    # openai_api_key=openai_api_key,\n",
    "    # openai_api_type=openai_api_type,\n",
    ")\n",
    "\n",
    "# llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith is a software tool that assists with localization and translation, rather than testing in the traditional software development sense. However, Langsmith can play a supportive role in ensuring the quality of multilingual software, applications, and documentation by streamlining the localization process. Here's how Langsmith can indirectly help with testing:\\n\\n1. **Consistency in Localization**: By providing consistent translations across different parts of an application or documentation, Langsmith helps maintain a uniform user experience, which is crucial for effective testing. Consistency reduces the likelihood of user confusion and errors during testing.\\n\\n2. **Automated Translation Suggestions**: Langsmith can offer real-time translation suggestions, which can speed up the localization process and allow testers to focus on testing the functionality rather than the accuracy of translations.\\n\\n3. **Integration with Development Tools**: If Langsmith integrates with development and translation management systems, it can facilitate a smoother workflow where localized text can be tested in context, ensuring that the software behaves as expected in different languages.\\n\\n4. **Translation Quality Control**: Langsmith may have features that help maintain high-quality translations, such as glossary management, which can be important for testing content-sensitive applications where the meaning of terms must be preserved accurately.\\n\\n5. **Efficient Localization Updates**: When software is updated and new text strings are added, Langsmith can help quickly localize these strings so that testers can verify the new content in different languages without significant delays.\\n\\n6. **Reduced Cognitive Load for Testers**: By handling the complexities of localization, Langsmith allows testers to focus on functional, usability, and performance testing without worrying about translation inconsistencies or errors.\\n\\n7. **Cultural Adaptation**: Beyond translation, localization often includes cultural adaptation. Langsmith may provide insights or checks to ensure that not only is the language correct, but it’s also culturally appropriate. This is important for user interface testing and ensuring the product is suitable for its target market.\\n\\nWhile Langsmith is not a testing tool per se, its contribution to the localization process can make the overall testing phase more efficient by allowing testers to work with high-quality, localized content in a streamlined manner. This enables them to identify functional and linguistic issues effectively, ultimately contributing to a better product for global audiences.\")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langsmith is an AI-powered tool designed to assist with a variety of language-related tasks, which can include testing in different contexts. If you are looking to understand how Langsmith can help with testing, here are a few scenarios:\\n\\n1. **Language Proficiency Testing**: Langsmith could potentially be used to help create tests for language proficiency. The AI might generate questions, provide translations, or even help with grading by evaluating the language used in responses.\\n\\n2. **Software Localization Testing**: If you're testing the localization of a software application, Langsmith could assist by checking the accuracy of translations, ensuring that phrases and idioms are correctly adapted to the target language, and confirming that the context is maintained.\\n\\n3. **Documentation Review**: For technical documentation, Langsmith can help test the clarity, readability, and understandability of the text. It can suggest improvements, correct grammar, and ensure that the language used is appropriate for the intended audience.\\n\\n4. **Automated Testing Scripts**: In software testing, Langsmith could potentially be used to write or review automated testing scripts, ensuring that the language and instructions are clear and precise.\\n\\n5. **Educational Testing**: For educational purposes, Langsmith could be used to draft or proofread test questions and answers, ensuring they are free of language errors and are phrased clearly to avoid any ambiguity.\\n\\n6. **UI/UX Testing**: Langsmith can help ensure that user interface elements are labeled and described correctly, enhancing the overall user experience with clear and concise language.\\n\\n7. **Quality Assurance**: Langsmith can assist in QA processes by checking error messages, notifications, and other text within an application to ensure they are well-written and informative.\\n\\n8. **Compliance Testing**: In industries with specific regulatory requirements regarding language use, Langsmith can help ensure that documents, software interfaces, and other materials meet these standards.\\n\\nKeep in mind that the effectiveness of Langsmith in these scenarios will depend on the specific features and capabilities of the tool at the time of use, as well as the context in which it is being applied. It is also important to note that while AI tools can provide significant assistance, human oversight is often necessary to ensure the highest quality outcomes, especially when nuanced language understanding or complex subject matter is involved.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "promt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    "    )\n",
    "promt_template.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a joke\"\n",
    ")\n",
    "\n",
    "promt_template.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke about sports, make it funny\\n\\nand in spanish'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = (\n",
    "    PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "    + \", make it funny\"\n",
    "    + \"\\n\\nand in {language}\"\n",
    ")\n",
    "#prompt\n",
    "prompt.format(topic=\"sports\", language=\"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"క్రికెట్ మ్యాచ్\\u200cలో ఒక ఆటగాడు ఎందుకు కూరగాయల దుకాణం తెరిచాడు?\\n\\nఎందుకంటే అతను ఎక్కువగా 'క్యాచ్'లు వదులుతూ ఉండడం వల్ల!\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = llm\n",
    "chain = LLMChain(llm=model,prompt=prompt)\n",
    "chain.run(topic=\"sports\",language=\"telugu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: you are a nice pirate\\nHuman: hi\\nAI: what?\\nHuman: i said hi'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "prompt = SystemMessage(content=\"you are a nice pirate\")\n",
    "new_prompt = prompt + HumanMessage(content=\"hi\") + AIMessage(content=\"what?\") + \"{input}\"\n",
    "new_prompt.format(input=\"i said hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ahoy matey! Greetings to ye on this fine day! How can I assist ye on your quest for knowledge or adventure?'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=model,prompt=new_prompt)\n",
    "chain.run(\"i said hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
       " HumanMessage(content='Hello, how are you doing?'),\n",
       " AIMessage(content=\"I'm doing well, thanks!\"),\n",
       " HumanMessage(content='What is your name?')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_val = prompt_template.invoke({\"adjective\": \"funny\", \"content\": \"chickens\"})\n",
    "prompt_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
